\section{Research Proposal}
\label{sec:proposal}

\subsection{Problem Statement}
\label{sec:proposal-problem}

The gap analysis in Section~\ref{sec:lit-synthesis} identified three interdependent categories of unresolved challenge: (a)~no existing system tightly integrates persistent knowledge graphs with autonomous multi-agent research workflows; (b)~no validated evaluation framework addresses AI-generated research outputs; and (c)~no generalizable mechanism enforces provenance---the traceable linkage between a generated claim and the specific evidence that supports it. These gaps form a cycle: without persistent knowledge infrastructure, provenance tracking is infeasible; without provenance, rigorous evaluation is impossible; and without evaluation criteria, architectural design lacks a target to optimize against.

We propose to break this cycle by addressing provenance and architectural integration simultaneously. The central research question is: \emph{How can semi-autonomous agentic research systems enforce span-level evidence alignment and canonicalization auditing across documents, such that every generated output is traceable to specific source evidence within persistent, structured knowledge infrastructure?} Existing systems either maintain structured knowledge without agentic reasoning (KG-RAG~\cite{suryawanshi2025kgrag}) or reason autonomously without structured provenance (Denario~\cite{villaescusa2025denario}). Neither supports what we term \emph{research progression}: the structured continuation, evaluation, and validation of research problems across sessions and documents. The proposed research addresses this gap directly.

\subsection{Proposed Approach}
\label{sec:proposal-approach}

We propose \emph{agentic knowledge graphs for research progression}: a provenance-first architecture organized into three integrated layers. While instantiated here using knowledge graphs as the primary substrate, the architecture's provenance-enforcement patterns are designed to generalize across persistent knowledge representations, including hybrid KG-vector stores or future alternatives.

\textbf{Knowledge representation layer.} At the core is a persistent research knowledge graph in which \emph{research problems}---not merely papers or claims---are modeled as first-class entities. Graph structure is particularly suited to this domain because research knowledge is inherently non-hierarchical: problems, datasets, methods, constraints, and evidence participate in many-to-many relationships that tabular or tree-based representations cannot naturally express. Here, a research problem denotes a tractable, scoped question with identifiable assumptions, methods, and evaluation criteria, extracted from one or more source documents. Because problem boundaries may be fluid across papers---what one study frames as a single problem, another may decompose into sub-problems---automated extraction is supplemented by human validation at defined checkpoints. Each problem node carries structured attributes including assumptions, constraints, datasets, metrics, and evidence spans anchored to source documents via identifiers and quoted text. Problems are linked through explicit semantic relations such as \emph{extends}, \emph{contradicts}, and \emph{depends-on}, enabling queries infeasible with citation-only models, such as tracing how a problem evolves across studies or identifying problems with shared constraints. A hybrid symbolic--semantic design pairs the property graph with a vector index, supporting both structured filtering and approximate similarity search. This layer draws on the entity extraction and community detection methods of Suryawanshi et al.~\cite{suryawanshi2025kgrag} but extends them from static pipelines to an evolving graph that accumulates knowledge across sessions---partially addressing the cumulative learning gap.

\textbf{Automation and extraction layer.} Research papers are ingested and transformed into structured graph entities through extraction pipelines combining heuristics with LLM-driven structured prompting. All extracted elements are linked to explicit evidence spans in the source document, providing provenance coverage subject to extraction reliability constraints. Span-level evidence alignment is enforced architecturally: the pipeline produces claim--evidence pairs rather than free-text output, embedding provenance as an architectural design constraint rather than a post-hoc annotation. Entity references across documents are resolved to canonical knowledge graph nodes through normalization, validation, and deduplication, enabling partial automated verification of whether cited evidence supports derived claims. This directly addresses the provenance and faithfulness gap from Section~\ref{sec:lit-synthesis}.

\textbf{Agentic orchestration layer.} Specialized agents operate over the structured graph to support research progression. Adapting Denario's~\cite{villaescusa2025denario} Planning \& Control pattern, the orchestration layer introduces role-specific agents: \emph{ranking agents} prioritize problems by tractability and evidence strength; \emph{continuation agents} propose follow-on experiments or analyses grounded in problem context; \emph{evaluation agents} execute reproducible workflows; and \emph{synthesis agents} write results back into the graph as new structured artifacts. Crucially, agents consume and produce structured graph objects rather than free text, and each agent handoff carries provenance constraints requiring downstream agents to inherit and extend the evidence chains established upstream. Consistent with the recommendations of Trinkenreich et al.~\cite{trinkenreich2025train} and Denario's authors~\cite{villaescusa2025denario}, human researchers validate outputs at defined checkpoints, ensuring the system augments rather than replaces research judgment.

This closed-loop design---where extracted problems are ranked, extended, evaluated, and written back into the graph---transforms the knowledge graph from a static repository into an active substrate for research progression. What is novel is the tight integration: enforcing span-level provenance as an architectural constraint across all three layers, rather than treating knowledge representation and agentic reasoning as separate concerns. Unlike traditional RAG systems, which retrieve documents per query without persistent state, this architecture maintains canonical entity resolution across documents, preserves cross-session knowledge evolution, enforces provenance inheritance across agent handoffs, and constructs claims from validated graph objects rather than unstructured retrieval context.

\subsection{Expected Contributions}
\label{sec:proposal-contributions}

This research program advances three primary contributions, each addressing a specific gap from Section~\ref{sec:lit-synthesis}.

\emph{First}, a reference architecture for provenance-enforcing agentic research systems that tightly integrates persistent knowledge graphs with multi-agent workflows, addressing the architectural capability gap. The architecture specifies interfaces between knowledge graph operations, agent reasoning, and human validation checkpoints, with research problems as first-class entities linked by explicit semantic relations.

\emph{Second}, a provenance evaluation framework organized around concrete research questions: extraction reliability (precision, recall, and F1 of structured problem extraction against human annotations), graph-based retrieval quality (MRR and nDCG compared against text- and citation-based baselines), progression utility (whether researchers using the system identify actionable continuations more effectively than with existing tools), and claim-evidence faithfulness (entailment verification, evidence sufficiency, and provenance completeness of generated outputs). These metrics directly address the evaluation gap by providing the operationalized constructs that Ralph et al.~\cite{ralph2021empirical} and Baltes et al.~\cite{baltes2025guidelines} identify as essential but that current agentic systems lack.

\emph{Third}, a reproducibility protocol for provenance-enforcing agentic research, specifying what artifacts must be preserved---knowledge graph snapshots, agent interaction logs, provenance chains, human validation decisions---to enable independent verification of research outputs. This protocol extends the reporting guidelines of Baltes et al.~\cite{baltes2025guidelines} to the specific case of autonomous research agents.

\subsection{Scope and Limitations}
\label{sec:proposal-limitations}

This proposal targets provenance-enforced research progression specifically; it does not claim to solve the broader challenges of autonomous scientific discovery. Although the proposed architecture uses knowledge graphs as its primary substrate, the core provenance-enforcement principles---span-level evidence alignment, canonicalization auditing, and structured agent handoffs---are not inherently KG-specific and may extend to hybrid or alternative persistent knowledge representations as the field evolves. The system remains bounded by the distribution of its source literature and the parametric knowledge of its underlying LLMs---it can organize, trace, and validate existing knowledge more reliably, but it does not generate genuinely novel hypotheses beyond what its evidence base supports. Extraction accuracy depends on LLM reliability and paper quality; implicit or ambiguous claims may resist structured extraction despite schema validation and human review. Mechanistic interpretability~\cite{sharkey2025mechanistic} may eventually provide deeper insight into agent decision-making, but the proposed architecture addresses provenance at the architectural level rather than at the model-internal level. Finally, the human-in-the-loop design deliberately trades full autonomy for verifiability---a constraint we view as appropriate given the current maturity of agentic research systems.
