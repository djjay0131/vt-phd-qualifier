\section{Conclusion}
\label{sec:conclusion}

As semi-autonomous agentic systems move into sustained research use, they expose a structural misalignment between capability and accountability. This synthesis identified a consistent divide: existing approaches either maintain structured knowledge without autonomous reasoning, or reason autonomously without enforceable provenance. None yet supports cumulative, provenance-enforced research progression across sessions and documents.

To address this gap, we proposed a provenance-first architectural framework integrating persistent knowledge graphs with multi-agent orchestration, treating span-level evidence alignment and canonicalization auditing as architectural invariants. Together with a faithfulness-centered evaluation framework and a reproducibility protocol, this approach reframes provenance from a reporting guideline into foundational research infrastructure.

The proposed system remains bounded by its source literature and deliberately retains human oversight. However, if semi-autonomous agents are to participate in long-horizon research programs, they must operate within infrastructure supporting persistence, traceability, and evaluability. Establishing such infrastructure is a prerequisite for accountable AI-assisted research ecosystems.